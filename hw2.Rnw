\documentclass{article}

\usepackage[margin=0.25in]{geometry}
\usepackage{fancyhdr}
\pagestyle{fancy}

\rhead{Andrea Mack and Kenny Flagg}
\chead{STAT 537 Homework 2}
\lhead{01/27/2016}


\setlength{\headheight}{20pt}

\renewcommand{\headrulewidth}{1pt}

\renewcommand{\footrulewidth}{0.2pt}

\begin{document}
\begin{enumerate}
\item

<<data, echo=FALSE, cahce=FALSE>>=
#setwd("C:/Users/Andrea Mack/OneDrive/Spring2016Courses/Stat537/Homework/HW2")
#load("easy_winresults_sp535_fg100.RData")
#results

air<-read.table(file = "http://people.stern.nyu.edu/wgreene/Text/tables/TableF7-1.txt", header = TRUE)
str(air)
air$T <- as.factor(air$T)
air$I <- as.factor(air$I)

#install.packages("MuMIn")
library("MuMIn")

options(na.action ="na.fail") #can't be na.exclude bc then models fit with different observations

# I = airline
# T = year
# Q = Output
# C = total cost
# PF = fuel price
# LF = load factor

air.full <- lm(C ~ Q + PF + LF, data = air)
air.d <- dredge(air.full, rank = AIC)
get.models(air.d, subset = TRUE)

summary(air.full)







@

<<kennys, include=FALSE>>=
n <- 90
CVn_j <- numeric(0)
for(j in 1:n){
  # Compare jth observation with mean omitting jth observation
  CVn_j[j] <- (air$C[j] - mean(air$C[-j]))^2
}
CVn <- mean(CVn_j)

#Let's discuss this one tomorrow.

CVn

@

\item There is strong support that the full model, with all three predictors explains the variation in the data better than any other model with fewer predictors because the all other models have AICs more than 2 units larger than the full model.

\item The AIC method for comparing the fullest model to the most reduced model yields the same result as the regression output for this comparison. The model with no predictors has an AIC 256.85 units larger than the full model. Based on a pvalue that is $< 1/1000$ ($F_{3,86} = 503.1$), there is strong evidence that the full model does better in explaning the variation in the data than a model without any predictors.

\item text four

\item Calculating $CV_(n)$ using leverage.

<<cvn.lev, echo=FALSE, cache=FALSE>>=
CVn.rank1_i <- numeric (0)

for(i in n){
air.inf <- influence(air.full) #calculates influence air.inf$hat[j]
air.pred <- predict(air.full)

CVn.rank1_i[i] <- (((air$C[i] - air.pred[i]))/(1 - air.inf$hat[i]))^2
}


CVn.rank1_lev <- 1/n + sum(CVn_i)


air2.lm <- lm(C ~ , data = air) #come back and fill in when dredge works
airlow.lm <- lm(C ~ , data = air)

# get.models returns a list of lm objects, ordered from best to worst
air2.lm <- get.models(air.d, subset = TRUE)[[2]]
airlow.lm <- get.models(air.d, subset = TRUE)[[8]]


CVn.rank2_i <- numeric(0)
for(i in n){
air2.inf <- influence(air2.lm) #calculates influence air.inf$hat[j]
air2.pred <- predict(air2.lm)

CVn.rank2_i[i] <- (((air$C[i] - air2.pred[i]))/(1 - air2.inf$hat[i]))^2

}
CVn.rank2_lev <- 1/n + sum(CVn.rank2_i)

CVn.ranklow_i <- numeric(0)
for(i in n){
airlow.inf <- influence(airlow.lm) #calculates influence air.inf$hat[j]
airlow.pred <- predict(airlow.lm)

CVn.ranklow_i[i] <- (((air$C[i] - airlow.pred[i]))/(1 - airlow.inf$hat[i]))^2

}
CVn.ranklow_lev <- 1/n + sum(CVn.ranklow_i)

c(CVn.rank1_lev, CVn.rank2_lev, CVn.rank2_lev)


########### CHECK ##############
#install.packages("cvTools")
library(cvTools)

folds.loocv <- cvFolds(n=n, K=n, R=1) #cvFolds object for LOOCV

# cvLM computes sqrt(CVn), so we need to square its output
cvLm(air.full, folds = folds.loocv)$cv^2
cvLm(air2.lm, folds = folds.loocv)$cv^2
cvLm(airlow.lm, folds = folds.loocv)$cv^2

# Checking that this agrees with #4
cvLm(lm(C ~ 1, data = air), folds = folds)$cv^2
CVn
@

\item 5-fold CV using cvFolds

<<cvfolds, echo=FALSE, cache=FALSE>>=
folds.5fold <- cvFolds(n=n, K=5, R=1) #cvFolds object for 5-fold CV

cvLm(air.full, folds = folds.5fold)$cv^2
cvLm(air2.lm, folds = folds.5fold)$cv^2
cvLm(airlow.lm, folds = folds.5fold)$cv^2
@

\end{enumerate}
\end{document}